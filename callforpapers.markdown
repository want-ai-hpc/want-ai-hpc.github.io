---
layout: page
title: Call for Papers
permalink: /neurips2023/callforpapers
---

We invite researchers and practitioners to submit their  work to the **WANT@NeurIPS2023**, which aims to explore cutting-edge advancements in neural network training and address the challenges associated with training models at scale as well as under limited resources.

<!-- - Abstract submission deadline: **September 22 (AOE), 2023** -->

- Full paper submission (all authors must have an OpenReview profile when submitting) deadline: ~~September 29 (AOE), 2023~~ **October 6 (AOE), 2023**

- Author notification: **October 27 (AOE), 2023**

- Camera-ready, poster, and video (optionally) submission: to be announced

- Submission link: [OpenReview](https://openreview.net/group?id=NeurIPS.cc/2023/Workshop/WANT) (double-blind review process)

<!-- - The site will start accepting submissions on August 9, 2023. -->

- Submission format: **full paper (up to 9 pages)** or **short paper (up to 4 pages)** plus unlimited references and appendix. Submitted `.pdf` file should satisfy [formatting templates](https://github.com/want-ai-hpc/want_neurips_2023_templates) (`.tex`, `.sty`)

- Submission to the workshop is non-archival (i.e. double submission is allowed, accepted papers will be posted on the workshop website) 

- We consider creating a special journal issue, all workshop contributors will have an opportunity to submit there (journal submission deadline is expected to be after the event on December 16, journal version of the paper might be an extended version of the OpenReview submission)


We welcome submissions on the following topics, but not limited to:

- Model/tensor/data and other types of parallelisms
- Pipelining
- Communication optimization
- Re-materialization (activation checkpointing)
- Offloading 
- Efficient computations: tensorized layers, low-precision computations, etc.
- Energy-efficient training
- Efficient data loading and preprocessing
- Network-aware resource allocation
- Architecture-aware resource allocation
- Scheduling for AI
